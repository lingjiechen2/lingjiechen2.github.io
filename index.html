<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Jon Barron and Deepak Pathak and Abhishek Kar and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 400
  }
  heading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 17px; /* 19 */
    font-weight: 600 /* 1000 */
  }
  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
  strong {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 600 /* 800 */
  }
  strongred {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 28px;
    font-weight: 600
  }
  pageheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 38px;
    font-weight: 400
  }
  .ImageBorder
  {
      border-width: 1px;
      border-color: Black;
  }
  </style>
  <link rel="shortcut icon" href="images/orange_icon_3.png">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Lingjie Chen</title>
  <meta name="Lingjie Chen's Homepage" http-equiv="Content-Type" content="Lingjie Chen's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <!-- Start : Google Analytics Code -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-XXXXX-Y', 'auto');
    ga('send', 'pageview');
    </script>
  <!-- End : Google Analytics Code -->
  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>
 
<body>
<table width="900" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center">
    <pageheading>Lingjie Chen 「陈凌杰」</pageheading><br>
  </p>

  <tr>
    <td width="30%" valign="top"><a href="images/LingjieChen.jpg"><img src="images/LingjieChen.jpg" width="100%" style="border-radius:15px"></a>
    <p align=center>
    <a href="data/Resume_Lingjie.pdf" target="_blank">Resume</a> |
    <a href="mailto:lingjiechen127@gmail.com">Email</a> | 
    <!-- <a href="https://scholar.google.com/citations?user=wMcPTbEAAAAJ&sortby=pubdate">G Scholar</a> |
    <br/>  -->
    <a href="https://github.com/lingjiechen2">Github</a> | 
    <!-- <a href="https://twitter.com/zipengfu">Twitter</a> | -->
    <a href="https://www.linkedin.com/in/lingjie-chen-b98a64290/">LinkedIn</a> |
    </p>
    </td>
    <td width="70%" valign="top" align="justify">
    <p>
      Hi there, I'm Jason Chen! I'm an incoming Ph.D. student at the University of Illinois Urbana-Champaign (UIUC), where I will be advised by Professor Hanghang Tong.
    </p>
    <p>
      My research primarily focuses on <strong>LLM Alignment</strong> and <strong>Mechanistic Interpretability</strong>.  
      My ultimate goal is to <strong>develop more transparent and controllable large language models by unifying trustworthiness with mechanistic interpretability</strong>.  
      Currently, I am exploring the <strong>fragility of LLMs</strong>, aiming to both reveal their vulnerabilities and devise methods that leverage mechanistic interpretability to analyze their internal structures.
    </p>
    </td>
  </tr>
</table>

<hr/>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Publications</sectionheading></td></tr>
</table>


  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">


    <tr>
      <td width="40%" valign="top" align="center"><a href="data/WAPITI A WATERMARK FOR FINETUNED OPENSOURCE LLMS.pdf"><img src="images/intro_image_WAPITTI_00.png" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></a></td>
      <td width="60%" valign="top">
        <p><a href="data/WAPITI A WATERMARK FOR FINETUNED OPENSOURCE LLMS.pdf" id="wapiti_watermark">
        <heading>WAPITI: A Watermark for Finetuned Open-Source LLMs</heading></a><br>
        <strong>Lingjie Chen*</strong>, Ruizhong Qiu*, Siyu Yuan, Zhining Liu, Tianxin Wei, Hyunsik Yoo, Zhichen Zeng, Deqing Yang, Huanghang Tong<br>
        ICLR 2025 Under Reivew</b>
        </p>

        <div class="paper" id="wapiti_watermark">
        <a href="data/WAPITI A WATERMARK FOR FINETUNED OPENSOURCE LLMS.pdf">pdf</a> |
        <a href="javascript:toggleblock('wapiti_watermark_abs')">abstract</a> |
        <a href="https://github.com/lingjiechen2/WAPITTI">Github</a> |
        <a href="https://arxiv.org/abs/2410.06467">arXiv</a> |
        <a shape="rect" href="javascript:togglebib('wapiti_watermark')" class="togglebib">bibtex</a>

        <p align="justify"><i id="wapiti_watermark_abs">Watermarking of large language models (LLMs) generation embeds an imperceptible statistical pattern within texts, making it algorithmically detectable. 
          Watermarking is a promising method for addressing potential harm and biases from LLMs, as it enables traceability, accountability, and detection of manipulated content, helping to mitigate unintended consequences. 
          However, for open-source models, watermarking faces two major challenges: 
          <strong>(i) incompatibility with fine-tuned models
          (ii) vulnerability to fine-tuning attacks.</strong>
          In this work, we propose <strong>WAPITI</strong>, a new method that transfers watermarking from base models to fine-tuned models through parameter integration.
          To the best of our knowledge, we propose the first watermark for fine-tuned open-source LLMs that preserves their fine-tuned capabilities. 
          Furthermore, our approach offers an effective defense against fine-tuning attacks. 
          We test our method on various model architectures and watermarking strategies. 
          Results demonstrate that our method can successfully inject watermarks and is highly compatible with fine-tuned models. 
          Additionally, we offer an in-depth analysis of how parameter editing influences the watermark strength and overall capabilities of the resulting models.</i></p>

<!-- <pre xml:space="preserve">
@article{yao2019energy,
  author = {Yao, Donghuan and Liang, Xiaohui and Fu, Zipeng and Zhang, Kai and Yang, Baojia},
  journal= {IEEE Internet of Things Journal},
  year   = {2019}
}
</pre> -->
      </div>
    </td>
  </tr>


    <tr>
      <td width="40%" valign="top" align="center"><a href="data/A Mechanistic View of Intrinsic Multilingualism in Large Language Models.pdf"><img src="images/conceptual_model_demo.png" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></a></td>
      <td width="60%" valign="top">
        <p><a href="data/A Mechanistic View of Intrinsic Multilingualism in Large Language Models.pdf" id="multilingual_interp">
        <heading>A Mechanistic View of Transferred and Intrinsic Multilingualism in Large Language Models</heading></a><br>
        <strong>Lingjie Chen*</strong>, Fukang Zhu*, Ningyu Xu, Xuyang Ge, Junxuan Wang, Zhengfu He, Xipeng Qiu<br>
        ICLR 2025 Under Reivew</b>
        </p>

        <div class="paper" id="multilingual_interp">
        <a href="data/A Mechanistic View of Intrinsic Multilingualism in Large Language Models.pdf">pdf</a> |
        <a href="javascript:toggleblock('multilingual_interp_abs')">abstract</a> |
        <a shape="rect" href="javascript:togglebib('multilingual_interp')" class="togglebib">bibtex</a>

        <p align="justify"><i id="multilingual_interp_abs">It has been conjectured that multilingual models process information in low-resource languages in an English state of mind since English takes up a large proportion of the training corpus. Recent progress in language model multilingualism provides more evidence for this hypothesis. We ask a further question: <strong>What if the model is trained on more than one high-resource language?</strong> By studying language models trained mostly on Chinese and English with an interpretability technique called Sparse Autoencoders, we manage to identify a three-stage process of how models think in these two languages. The model first 'detokenizes' inputs and both languages are aligned. The representation of these two languages then diverges and is processed independently in a 'conceptual stage' and is aligned again in the 'retokenization stage'. We name this after the <em>Intrinsic Multilingualism</em>. We empirically test our hypothesis by intervening the model internal with Sparse Autoencoders trained on another language and find that the 'conceptual stage' is crucial for the model to think in different languages. We also showcase a number of features detecting intriguing lingual and cultural bias in Chinese and English.</i></p>

<!-- <pre xml:space="preserve">
@article{yao2019energy,
  author = {Yao, Donghuan and Liang, Xiaohui and Fu, Zipeng and Zhang, Kai and Yang, Baojia},
  journal= {IEEE Internet of Things Journal},
  year   = {2019}
}
</pre> -->
      </div>
    </td>
  </tr>



  <tr>
   <td width="30%" valign="top" align="center">
    <a href="https://arxiv.org/abs/2404.13599">
    <img src="images/pun2024_cropped.png" alt="sym" width="100%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></img>
    </a></td>
    <td width="70%" valign="top">
      <p><a href="https://manipulation-locomotion.github.io" id="pun">
      <heading>"A good pun is its own reword": Can Large Language Models Understand Puns?</heading></a><br>
      Zhijun Xu, Siyu Yuan,  <strong>Lingjie Chen</strong>, Deqing Yang<br>
      <strong>EMNLP 2024 Main</strong><br>
      <!-- <b style="color:rgb(255, 100, 100);">Best Systems Paper Award Finalist (top 4)</b> -->
      </p>

      <div class="paper" id="pun">
      <!-- <a href="https://manipulation-locomotion.github.io">webpage</a> | -->
      <a href="data/A_good_pun_is_its_own_reword.pdf">pdf</a> |
      <a href="javascript:toggleblock('pun_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('pun')" class="togglebib">bibtex</a> |
      <a href="https://arxiv.org/abs/2404.13599">arXiv</a> |
      <!-- <a href="https://www.youtube.com/watch?v=i9EdPl8uJUA">video</a> -->

      <p align="justify"> <i id="pun_abs">As one of the common rhetorical devices, puns play a vital role in linguistic study, including the comprehensive analysis of linguistic humor. Although large language models (LLMs) have been widely explored on various tasks of natural language understanding and generation, their ability to understand puns has not been systematically studied, limiting the utilization of LLMs in creative writing and humor creation. In this paper, we leverage three popular tasks, i.e., pun recognition, pun explanation, and pun generation, to systematically evaluate LLMs' capability of understanding puns. In addition to the evaluation metrics adopted by prior research, we introduce some new evaluation methods and metrics that are better suited to the in-context learning paradigm of LLMs. These new metrics offer a more rigorous assessment of an LLM's capability to understand puns and align more closely with human cognition. Our research findings reveal the “lazy pun generation” pattern and identify the primary challenges in understanding puns with LLMs.</i></p>
        </div>
      </td>
    </tr>
  

</table>


<hr/>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Projects</sectionheading></td></tr>
</table>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
  <tr>
    <td width="100%" valign="top">
      <p><a href="https://github.com/OpenMOSS/Language-Model-SAEs/tree/main" id="MOBILE_ALOHA">
      <heading>Language-Model-SAEs</heading></a><br>
      </p>
      <div class="paper" id="mobile_aloha">
      <a href="https://github.com/OpenMOSS/Language-Model-SAEs/tree/main">Github</a> |
      <a href="data/llama_scope_EXTRACTING MILLIONS OF FEATURES FROM LLAMA-3.1-8B WITH SPARSE AUTOENCODERS.pdf">Report</a> 
      <p align="justify">
        <i id="BERT_ABS">
          This repo aims to provide a general codebase for conducting <strong>dictionary-learning-based mechanistic interpretability</strong> research on Language Models (LMs). It powers a configurable pipeline for training and evaluating Sparse Autoencoders and their variants, and provides a set of tools (mainly a React-based webpage) for analyzing and visualizing the learned dictionaries.
        </i>
      </p>
    
      <!-- <a href="javascript:toggleblock('QA_BERT_abs')">abstract</a> |      -->

      <!-- <p align="justify"> <i id="QA_BERT_abs">This research investigates the efficacy of a lightweight, monolingual Bert model specifically tailored for Chinese Question Answering (QA) tasks. By employing a range of advanced training techniques, the model achieved a notable milestone, placing within the top 20 in Kaggle’s renowned QA competition. Our findings reveal a surprisingly narrow performance gap between the specialized Bert model and larger Language Learning Models (LLMs), highlighting the potential of focused, language-specific approaches in the realm of natural language processing.</i></p> -->
      </div>
    </td>
  </tr>
</table>


<hr/>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Reviewer Services</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
  <tr>
    <td valign="top">
      <p style="margin: 2px 0;">International Conference on Learning Representations (<strong>ICLR</strong>), 2024, 2025</p>
      <p style="margin: 2px 0;">Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>), 2025</p>
      <p style="margin: 2px 0;">Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>), 2024</p>
    </td>
  </tr>
</table>



<table width="100%" align="center" border="0" cellspacing="0" cellpadding="2">
    <tr><td><br><p align="right">
    Website template from <a href="http://www.cs.berkeley.edu/~barron/">here</a> and <a href="http://www.cs.cmu.edu/~dpathak/">here</a>
    </font></p></td></tr>
</table>




  </td></tr>
</table>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('wapiti_watermark_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('multilingual_interp_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('pun_abs');
</script>
</body>

</html>
